{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Dataset\n",
      "BOW Dataset\n",
      "TFIDF Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x9991</th>\n",
       "      <th>x9992</th>\n",
       "      <th>x9993</th>\n",
       "      <th>x9994</th>\n",
       "      <th>x9995</th>\n",
       "      <th>x9996</th>\n",
       "      <th>x9997</th>\n",
       "      <th>x9998</th>\n",
       "      <th>x9999</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.177057</td>\n",
       "      <td>0.063437</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.407604</td>\n",
       "      <td>0.119183</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.047931</td>\n",
       "      <td>0.117364</td>\n",
       "      <td>0.046370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17495</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17500 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label        x0        x1        x2        x3        x4        x5  \\\n",
       "0          1  0.177057  0.063437  0.083603  0.407604  0.119183  0.096883   \n",
       "1          1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2         -1  0.000000  0.109398  0.000000  0.000000  0.000000  0.000000   \n",
       "3          1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4          1  0.000000  0.000000  0.044455  0.000000  0.000000  0.000000   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "17495      1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17496      1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17497     -1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17498     -1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17499     -1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             x6        x7        x8  ...  x9991  x9992  x9993  x9994  x9995  \\\n",
       "0      0.047931  0.117364  0.046370  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.020774  0.000000  0.020098  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "17495  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "17496  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "17497  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "17498  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "17499  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       x9996  x9997  x9998  x9999  bias  \n",
       "0        0.0    0.0    0.0    0.0     1  \n",
       "1        0.0    0.0    0.0    0.0     1  \n",
       "2        0.0    0.0    0.0    0.0     1  \n",
       "3        0.0    0.0    0.0    0.0     1  \n",
       "4        0.0    0.0    0.0    0.0     1  \n",
       "...      ...    ...    ...    ...   ...  \n",
       "17495    0.0    0.0    0.0    0.0     1  \n",
       "17496    0.0    0.0    0.0    0.0     1  \n",
       "17497    0.0    0.0    0.0    0.0     1  \n",
       "17498    0.0    0.0    0.0    0.0     1  \n",
       "17499    0.0    0.0    0.0    0.0     1  \n",
       "\n",
       "[17500 rows x 10002 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glove\n",
    "glove_df_train = pd.read_csv(\"../project_data/data/glove/glove.train.csv\")\n",
    "glove_df_test = pd.read_csv(\"../project_data/data/glove/glove.test.csv\")\n",
    "glove_df_eval = pd.read_csv(\"../project_data/data/glove/glove.eval.anon.csv\")\n",
    "\n",
    "# Add bias\n",
    "glove_df_train[\"bias\"] = 1\n",
    "glove_df_test[\"bias\"] = 1\n",
    "glove_df_eval[\"bias\"] = 1\n",
    "\n",
    "# Replace label 0 with -1\n",
    "glove_df_train.loc[glove_df_train[\"label\"] == 0, \"label\"] = -1\n",
    "glove_df_test.loc[glove_df_test[\"label\"] == 0, \"label\"] = -1\n",
    "glove_df_eval.loc[glove_df_eval[\"label\"] == 0, \"label\"] = -1\n",
    "\n",
    "glove_df_train\n",
    "\n",
    "# Bag of words\n",
    "bow_df_train = pd.read_csv(\"../project_data/data/bag-of-words/bow.train.csv\")\n",
    "bow_df_test = pd.read_csv(\"../project_data/data/bag-of-words/bow.test.csv\")\n",
    "bow_df_eval = pd.read_csv(\"../project_data/data/bag-of-words/bow.eval.anon.csv\")\n",
    "\n",
    "# Add bias\n",
    "bow_df_train[\"bias\"] = 1\n",
    "bow_df_test[\"bias\"] = 1\n",
    "bow_df_eval[\"bias\"] = 1\n",
    "\n",
    "# Replace label 0 with -1\n",
    "bow_df_train.loc[bow_df_train[\"label\"] == 0, \"label\"] = -1\n",
    "bow_df_test.loc[bow_df_test[\"label\"] == 0, \"label\"] = -1\n",
    "bow_df_eval.loc[bow_df_eval[\"label\"] == 0, \"label\"] = -1\n",
    "\n",
    "\n",
    "# Bag of words\n",
    "tfidf_df_train = pd.read_csv(\"../project_data/data/tfidf/tfidf.train.csv\")\n",
    "tfidf_df_test = pd.read_csv(\"../project_data/data/tfidf/tfidf.test.csv\")\n",
    "tfidf_df_eval = pd.read_csv(\"../project_data/data/tfidf/tfidf.eval.anon.csv\")\n",
    "\n",
    "# Add bias\n",
    "tfidf_df_train[\"bias\"] = 1\n",
    "tfidf_df_test[\"bias\"] = 1\n",
    "tfidf_df_eval[\"bias\"] = 1\n",
    "\n",
    "# Replace label 0 with -1\n",
    "tfidf_df_train.loc[tfidf_df_train[\"label\"] == 0, \"label\"] = -1\n",
    "tfidf_df_test.loc[tfidf_df_test[\"label\"] == 0, \"label\"] = -1\n",
    "tfidf_df_eval.loc[tfidf_df_eval[\"label\"] == 0, \"label\"] = -1\n",
    "\n",
    "print(\"Glove Dataset\")\n",
    "glove_df_train\n",
    "\n",
    "print(\"BOW Dataset\")\n",
    "bow_df_train\n",
    "\n",
    "print(\"TFIDF Dataset\")\n",
    "tfidf_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_key_by_value(map):\n",
    "    max_key = \"\"\n",
    "    max_val = float(\"-inf\")\n",
    "\n",
    "    for key, val in map.items():\n",
    "        if val > max_val:\n",
    "            max_val = val\n",
    "            max_key = key\n",
    "\n",
    "    # print(\"map: \", map, \"max_key: \", max_key)\n",
    "    return max_key\n",
    "\n",
    "\n",
    "def initialize_weights_bias(feature_count):\n",
    "    rand_start = -0.01\n",
    "    rand_end = 0.01\n",
    "    random_number = random.uniform(rand_start, rand_end)\n",
    "\n",
    "    bias = random_number\n",
    "    weights = []  # All weights and bias should be same.\n",
    "    for _ in range(feature_count):\n",
    "        weights.append(random_number)\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "def predict(weights, example):\n",
    "    value = np.dot(weights, example)\n",
    "    return 1 if value > 0 else -1\n",
    "\n",
    "\n",
    "def test_accuracy(df, weights, store_eval=False):\n",
    "    eval_list = []\n",
    "    total = df.shape[0]\n",
    "    correct_prediction = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        example = row.tolist()\n",
    "        actual_label = example[0]  # y\n",
    "        example = example[1:]  # x\n",
    "\n",
    "        predicted_label = predict(weights, example)\n",
    "        if predicted_label == actual_label:\n",
    "            correct_prediction += 1\n",
    "\n",
    "        if store_eval:\n",
    "            eval_list.append(predicted_label)\n",
    "\n",
    "    # print(f\"Test accuracy. Correct Pred: {correct_prediction}, Total: {total}\")\n",
    "    return correct_prediction / total, eval_list\n",
    "\n",
    "\n",
    "def export_prediction_to_csv(file_name, prediction_list):\n",
    "    # Change back -1 to 0\n",
    "    for index, p in enumerate(prediction_list):\n",
    "        if p == -1:\n",
    "            prediction_list[index] = 0\n",
    "\n",
    "    df = pd.DataFrame(prediction_list)\n",
    "    df.to_csv(file_name, index=True, index_label=\"example_id\", header=[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rates = [1, 0.1, 0.01]\n",
    "\n",
    "\n",
    "def simple_perceptron(df, learning_rate, weights):\n",
    "    for _, row in df.iterrows():\n",
    "        example = row.tolist()\n",
    "        actual_label = example[0]  # y\n",
    "        example = example[1:]  # x\n",
    "\n",
    "        value = actual_label * (np.dot(weights, example))\n",
    "\n",
    "        # update\n",
    "        if value < 0:\n",
    "            for index in range(len(weights)):\n",
    "                # w = w + r * y * x\n",
    "                weights[index] += learning_rate * actual_label * example[index]\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def simple_perceptron_setup(df_train, df_test):\n",
    "    best_weights = []\n",
    "    best_accuracy = 0.0\n",
    "    best_learning_rate = 0.0\n",
    "\n",
    "    initial_weights, _ = initialize_weights_bias(feature_count=df_train.shape[1] - 1)\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        weights = initial_weights[:]  # New learning rate start with same initial weights.\n",
    "        print(f\"\\n\\tLearning rate: {learning_rate}\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle the whole data frame.\n",
    "            df_train = df_train.sample(frac=1, random_state=1)\n",
    "\n",
    "            weights = simple_perceptron(df=df_train, learning_rate=learning_rate, weights=weights)\n",
    "            accuracy, _ = test_accuracy(df=df_test, weights=weights, store_eval=False)\n",
    "            print(f\"\\t\\tEpoch: {epoch + 1}, Accuracy: {accuracy}\")\n",
    "\n",
    "            if accuracy >= best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_weights = weights\n",
    "                best_learning_rate = learning_rate\n",
    "\n",
    "    return best_learning_rate, best_accuracy, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rates = [1, 0.1, 0.01]\n",
    "\n",
    "\n",
    "def average_perceptron(df, learning_rate, weights, avg_weights):\n",
    "    for _, row in df.iterrows():\n",
    "        example = row.tolist()\n",
    "        actual_label = example[0]  # y\n",
    "        example = example[1:]  # x\n",
    "\n",
    "        # y(wT x + b)\n",
    "        value = actual_label * (np.dot(weights, example))\n",
    "\n",
    "        # update\n",
    "        if value < 0:\n",
    "            for index in range(len(weights)):\n",
    "                # w = w + r * y * x\n",
    "                weights[index] += learning_rate * actual_label * example[index]\n",
    "\n",
    "        for index in range(len(weights)):\n",
    "            avg_weights[index] += weights[index]\n",
    "\n",
    "    return weights, avg_weights\n",
    "\n",
    "\n",
    "def average_perceptron_setup(df_train, df_test):\n",
    "    best_weights = []\n",
    "    best_accuracy = 0.0\n",
    "    best_learning_rate = 0.0\n",
    "\n",
    "    initial_weights, _ = initialize_weights_bias(feature_count=df_train.shape[1] - 1)\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        weights = initial_weights[:]  # New learning rate start with same initial weights.\n",
    "        avg_weights = initial_weights[:]  # Copy the list because list is mutable.\n",
    "        print(f\"\\n\\tLearning rate: {learning_rate}\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle the whole data frame.\n",
    "            df_train = df_train.sample(frac=1, random_state=1)\n",
    "\n",
    "            weights, avg_weights = average_perceptron(\n",
    "                df=df_train, learning_rate=learning_rate, weights=weights, avg_weights=avg_weights\n",
    "            )\n",
    "            accuracy, _ = test_accuracy(df=df_test, weights=avg_weights, store_eval=False)\n",
    "            print(f\"\\t\\tEpoch: {epoch + 1}, Accuracy: {accuracy}\")\n",
    "\n",
    "            if accuracy >= best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_weights = weights\n",
    "                best_learning_rate = learning_rate\n",
    "\n",
    "    return best_learning_rate, best_accuracy, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "margins = [1, 0.1, 0.01]\n",
    "\n",
    "def aggressive_perceptron(df, margin, weights):\n",
    "    for _, row in df.iterrows():\n",
    "        example = row.tolist()\n",
    "        actual_label = example[0]  # y\n",
    "        example = example[1:]  # x\n",
    "\n",
    "        # y(wT x + b)\n",
    "        learning_rate = (margin - (actual_label * (np.dot(weights, example)))) / (np.dot(example, example) + 1)\n",
    "        value = actual_label * (np.dot(weights, example))\n",
    "\n",
    "        # update\n",
    "        if value <= margin:\n",
    "            for index in range(len(weights)):\n",
    "                # w = w + r * y * x\n",
    "                weights[index] += learning_rate * actual_label * example[index]\n",
    "\n",
    "    return weights\n",
    "\n",
    "def aggressive_perceptron_setup(df_train, df_test):\n",
    "    best_weights = []\n",
    "    best_margin = 0.0\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    initial_weights, _ = initialize_weights_bias(feature_count=df_train.shape[1] - 1)\n",
    "\n",
    "    for margin in margins:\n",
    "        weights = initial_weights[:]  # New learning rate start with same initial weights.\n",
    "        print(f\"\\n\\tMargin: {margin}\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle the whole data frame.\n",
    "            df_train = df_train.sample(frac=1, random_state=1)\n",
    "\n",
    "            weights = aggressive_perceptron(df=df_train, margin=margin, weights=weights)\n",
    "            accuracy, _ = test_accuracy(df=df_test, weights=weights, store_eval=False)\n",
    "            print(f\"\\t\\tEpoch: {epoch + 1}, Accuracy: {accuracy}\")\n",
    "\n",
    "            if accuracy >= best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_weights = weights\n",
    "                best_margin = margin\n",
    "\n",
    "    return best_margin, best_accuracy, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Perceptron\n",
      "\n",
      "\tGlove Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.5906666666666667\n",
      "\t\tEpoch: 2, Accuracy: 0.6413333333333333\n",
      "\t\tEpoch: 3, Accuracy: 0.6048888888888889\n",
      "\t\tEpoch: 4, Accuracy: 0.6231111111111111\n",
      "\t\tEpoch: 5, Accuracy: 0.5662222222222222\n",
      "\t\tEpoch: 6, Accuracy: 0.6311111111111111\n",
      "\t\tEpoch: 7, Accuracy: 0.56\n",
      "\t\tEpoch: 8, Accuracy: 0.5324444444444445\n",
      "\t\tEpoch: 9, Accuracy: 0.5226666666666666\n",
      "\t\tEpoch: 10, Accuracy: 0.6084444444444445\n",
      "\t\tEpoch: 11, Accuracy: 0.5337777777777778\n",
      "\t\tEpoch: 12, Accuracy: 0.5688888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.6306666666666667\n",
      "\t\tEpoch: 14, Accuracy: 0.6417777777777778\n",
      "\t\tEpoch: 15, Accuracy: 0.528\n",
      "\t\tEpoch: 16, Accuracy: 0.5813333333333334\n",
      "\t\tEpoch: 17, Accuracy: 0.6373333333333333\n",
      "\t\tEpoch: 18, Accuracy: 0.5222222222222223\n",
      "\t\tEpoch: 19, Accuracy: 0.6284444444444445\n",
      "\t\tEpoch: 20, Accuracy: 0.5466666666666666\n",
      "\t\tEpoch: 21, Accuracy: 0.5631111111111111\n",
      "\t\tEpoch: 22, Accuracy: 0.5386666666666666\n",
      "\t\tEpoch: 23, Accuracy: 0.536\n",
      "\t\tEpoch: 24, Accuracy: 0.5262222222222223\n",
      "\t\tEpoch: 25, Accuracy: 0.6102222222222222\n",
      "\t\tEpoch: 26, Accuracy: 0.6026666666666667\n",
      "\t\tEpoch: 27, Accuracy: 0.6342222222222222\n",
      "\t\tEpoch: 28, Accuracy: 0.6204444444444445\n",
      "\t\tEpoch: 29, Accuracy: 0.624\n",
      "\t\tEpoch: 30, Accuracy: 0.6324444444444445\n",
      "\t\tEpoch: 31, Accuracy: 0.6022222222222222\n",
      "\t\tEpoch: 32, Accuracy: 0.5444444444444444\n",
      "\t\tEpoch: 33, Accuracy: 0.5933333333333334\n",
      "\t\tEpoch: 34, Accuracy: 0.5906666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.5493333333333333\n",
      "\t\tEpoch: 36, Accuracy: 0.5902222222222222\n",
      "\t\tEpoch: 37, Accuracy: 0.6155555555555555\n",
      "\t\tEpoch: 38, Accuracy: 0.6133333333333333\n",
      "\t\tEpoch: 39, Accuracy: 0.54\n",
      "\t\tEpoch: 40, Accuracy: 0.5417777777777778\n",
      "\t\tEpoch: 41, Accuracy: 0.5933333333333334\n",
      "\t\tEpoch: 42, Accuracy: 0.5168888888888888\n",
      "\t\tEpoch: 43, Accuracy: 0.6191111111111111\n",
      "\t\tEpoch: 44, Accuracy: 0.5404444444444444\n",
      "\t\tEpoch: 45, Accuracy: 0.5391111111111111\n",
      "\t\tEpoch: 46, Accuracy: 0.5977777777777777\n",
      "\t\tEpoch: 47, Accuracy: 0.6288888888888889\n",
      "\t\tEpoch: 48, Accuracy: 0.6128888888888889\n",
      "\t\tEpoch: 49, Accuracy: 0.5884444444444444\n",
      "\t\tEpoch: 50, Accuracy: 0.548\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.624\n",
      "\t\tEpoch: 2, Accuracy: 0.624\n",
      "\t\tEpoch: 3, Accuracy: 0.5653333333333334\n",
      "\t\tEpoch: 4, Accuracy: 0.5466666666666666\n",
      "\t\tEpoch: 5, Accuracy: 0.6026666666666667\n",
      "\t\tEpoch: 6, Accuracy: 0.58\n",
      "\t\tEpoch: 7, Accuracy: 0.5231111111111111\n",
      "\t\tEpoch: 8, Accuracy: 0.6253333333333333\n",
      "\t\tEpoch: 9, Accuracy: 0.5595555555555556\n",
      "\t\tEpoch: 10, Accuracy: 0.62\n",
      "\t\tEpoch: 11, Accuracy: 0.6488888888888888\n",
      "\t\tEpoch: 12, Accuracy: 0.5577777777777778\n",
      "\t\tEpoch: 13, Accuracy: 0.6093333333333333\n",
      "\t\tEpoch: 14, Accuracy: 0.6266666666666667\n",
      "\t\tEpoch: 15, Accuracy: 0.5173333333333333\n",
      "\t\tEpoch: 16, Accuracy: 0.6195555555555555\n",
      "\t\tEpoch: 17, Accuracy: 0.6404444444444445\n",
      "\t\tEpoch: 18, Accuracy: 0.5991111111111111\n",
      "\t\tEpoch: 19, Accuracy: 0.6151111111111112\n",
      "\t\tEpoch: 20, Accuracy: 0.6213333333333333\n",
      "\t\tEpoch: 21, Accuracy: 0.6368888888888888\n",
      "\t\tEpoch: 22, Accuracy: 0.6222222222222222\n",
      "\t\tEpoch: 23, Accuracy: 0.6124444444444445\n",
      "\t\tEpoch: 24, Accuracy: 0.6431111111111111\n",
      "\t\tEpoch: 25, Accuracy: 0.5813333333333334\n",
      "\t\tEpoch: 26, Accuracy: 0.6391111111111111\n",
      "\t\tEpoch: 27, Accuracy: 0.5533333333333333\n",
      "\t\tEpoch: 28, Accuracy: 0.6328888888888888\n",
      "\t\tEpoch: 29, Accuracy: 0.588\n",
      "\t\tEpoch: 30, Accuracy: 0.5213333333333333\n",
      "\t\tEpoch: 31, Accuracy: 0.6506666666666666\n",
      "\t\tEpoch: 32, Accuracy: 0.6333333333333333\n",
      "\t\tEpoch: 33, Accuracy: 0.6151111111111112\n",
      "\t\tEpoch: 34, Accuracy: 0.6235555555555555\n",
      "\t\tEpoch: 35, Accuracy: 0.6191111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.5244444444444445\n",
      "\t\tEpoch: 37, Accuracy: 0.5315555555555556\n",
      "\t\tEpoch: 38, Accuracy: 0.5386666666666666\n",
      "\t\tEpoch: 39, Accuracy: 0.5093333333333333\n",
      "\t\tEpoch: 40, Accuracy: 0.5964444444444444\n",
      "\t\tEpoch: 41, Accuracy: 0.6271111111111111\n",
      "\t\tEpoch: 42, Accuracy: 0.6151111111111112\n",
      "\t\tEpoch: 43, Accuracy: 0.5893333333333334\n",
      "\t\tEpoch: 44, Accuracy: 0.5035555555555555\n",
      "\t\tEpoch: 45, Accuracy: 0.588\n",
      "\t\tEpoch: 46, Accuracy: 0.6511111111111111\n",
      "\t\tEpoch: 47, Accuracy: 0.576\n",
      "\t\tEpoch: 48, Accuracy: 0.6253333333333333\n",
      "\t\tEpoch: 49, Accuracy: 0.532\n",
      "\t\tEpoch: 50, Accuracy: 0.6173333333333333\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.588\n",
      "\t\tEpoch: 2, Accuracy: 0.6235555555555555\n",
      "\t\tEpoch: 3, Accuracy: 0.6257777777777778\n",
      "\t\tEpoch: 4, Accuracy: 0.5395555555555556\n",
      "\t\tEpoch: 5, Accuracy: 0.504\n",
      "\t\tEpoch: 6, Accuracy: 0.6488888888888888\n",
      "\t\tEpoch: 7, Accuracy: 0.5333333333333333\n",
      "\t\tEpoch: 8, Accuracy: 0.548\n",
      "\t\tEpoch: 9, Accuracy: 0.5773333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.6186666666666667\n",
      "\t\tEpoch: 11, Accuracy: 0.6195555555555555\n",
      "\t\tEpoch: 12, Accuracy: 0.5866666666666667\n",
      "\t\tEpoch: 13, Accuracy: 0.5493333333333333\n",
      "\t\tEpoch: 14, Accuracy: 0.5377777777777778\n",
      "\t\tEpoch: 15, Accuracy: 0.5986666666666667\n",
      "\t\tEpoch: 16, Accuracy: 0.5893333333333334\n",
      "\t\tEpoch: 17, Accuracy: 0.6008888888888889\n",
      "\t\tEpoch: 18, Accuracy: 0.5613333333333334\n",
      "\t\tEpoch: 19, Accuracy: 0.5631111111111111\n",
      "\t\tEpoch: 20, Accuracy: 0.6057777777777777\n",
      "\t\tEpoch: 21, Accuracy: 0.6444444444444445\n",
      "\t\tEpoch: 22, Accuracy: 0.5493333333333333\n",
      "\t\tEpoch: 23, Accuracy: 0.5146666666666667\n",
      "\t\tEpoch: 24, Accuracy: 0.6582222222222223\n",
      "\t\tEpoch: 25, Accuracy: 0.6226666666666667\n",
      "\t\tEpoch: 26, Accuracy: 0.6417777777777778\n",
      "\t\tEpoch: 27, Accuracy: 0.6088888888888889\n",
      "\t\tEpoch: 28, Accuracy: 0.5995555555555555\n",
      "\t\tEpoch: 29, Accuracy: 0.5906666666666667\n",
      "\t\tEpoch: 30, Accuracy: 0.5471111111111111\n",
      "\t\tEpoch: 31, Accuracy: 0.5648888888888889\n",
      "\t\tEpoch: 32, Accuracy: 0.5888888888888889\n",
      "\t\tEpoch: 33, Accuracy: 0.5435555555555556\n",
      "\t\tEpoch: 34, Accuracy: 0.6168888888888889\n",
      "\t\tEpoch: 35, Accuracy: 0.6435555555555555\n",
      "\t\tEpoch: 36, Accuracy: 0.62\n",
      "\t\tEpoch: 37, Accuracy: 0.5071111111111111\n",
      "\t\tEpoch: 38, Accuracy: 0.6084444444444445\n",
      "\t\tEpoch: 39, Accuracy: 0.6248888888888889\n",
      "\t\tEpoch: 40, Accuracy: 0.568\n",
      "\t\tEpoch: 41, Accuracy: 0.5706666666666667\n",
      "\t\tEpoch: 42, Accuracy: 0.58\n",
      "\t\tEpoch: 43, Accuracy: 0.6288888888888889\n",
      "\t\tEpoch: 44, Accuracy: 0.5844444444444444\n",
      "\t\tEpoch: 45, Accuracy: 0.608\n",
      "\t\tEpoch: 46, Accuracy: 0.608\n",
      "\t\tEpoch: 47, Accuracy: 0.5764444444444444\n",
      "\t\tEpoch: 48, Accuracy: 0.636\n",
      "\t\tEpoch: 49, Accuracy: 0.5844444444444444\n",
      "\t\tEpoch: 50, Accuracy: 0.6422222222222222\n",
      "\n",
      "\tBest parameter: 0.01 & test accuracy:  0.6582222222222223\n",
      "\tBOW Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.6715555555555556\n",
      "\t\tEpoch: 2, Accuracy: 0.6591111111111111\n",
      "\t\tEpoch: 3, Accuracy: 0.6462222222222223\n",
      "\t\tEpoch: 4, Accuracy: 0.6604444444444444\n",
      "\t\tEpoch: 5, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 6, Accuracy: 0.6733333333333333\n",
      "\t\tEpoch: 7, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 8, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 9, Accuracy: 0.6755555555555556\n",
      "\t\tEpoch: 10, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 11, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 12, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 13, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 14, Accuracy: 0.6826666666666666\n",
      "\t\tEpoch: 15, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 16, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 17, Accuracy: 0.6764444444444444\n",
      "\t\tEpoch: 18, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 19, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 20, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 21, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 22, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 23, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 24, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 25, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 26, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 27, Accuracy: 0.696\n",
      "\t\tEpoch: 28, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 30, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 31, Accuracy: 0.688\n",
      "\t\tEpoch: 32, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 33, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 35, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 36, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 37, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 38, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 39, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 40, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 41, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 42, Accuracy: 0.7\n",
      "\t\tEpoch: 43, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 44, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 45, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 47, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 48, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 49, Accuracy: 0.6751111111111111\n",
      "\t\tEpoch: 50, Accuracy: 0.6866666666666666\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6608888888888889\n",
      "\t\tEpoch: 2, Accuracy: 0.6595555555555556\n",
      "\t\tEpoch: 3, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 4, Accuracy: 0.6693333333333333\n",
      "\t\tEpoch: 5, Accuracy: 0.6684444444444444\n",
      "\t\tEpoch: 6, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 7, Accuracy: 0.6697777777777778\n",
      "\t\tEpoch: 8, Accuracy: 0.6551111111111111\n",
      "\t\tEpoch: 9, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 10, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 11, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 12, Accuracy: 0.688\n",
      "\t\tEpoch: 13, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 14, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 15, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 16, Accuracy: 0.6728888888888889\n",
      "\t\tEpoch: 17, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 18, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 19, Accuracy: 0.6795555555555556\n",
      "\t\tEpoch: 20, Accuracy: 0.68\n",
      "\t\tEpoch: 21, Accuracy: 0.6848888888888889\n",
      "\t\tEpoch: 22, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 23, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 24, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 25, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 26, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 27, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 28, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.6968888888888889\n",
      "\t\tEpoch: 30, Accuracy: 0.688\n",
      "\t\tEpoch: 31, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 32, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 33, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 34, Accuracy: 0.6968888888888889\n",
      "\t\tEpoch: 35, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 36, Accuracy: 0.6755555555555556\n",
      "\t\tEpoch: 37, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 38, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 39, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 40, Accuracy: 0.6813333333333333\n",
      "\t\tEpoch: 41, Accuracy: 0.688\n",
      "\t\tEpoch: 42, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 43, Accuracy: 0.6813333333333333\n",
      "\t\tEpoch: 44, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 45, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 46, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 47, Accuracy: 0.6764444444444444\n",
      "\t\tEpoch: 48, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 49, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 50, Accuracy: 0.6844444444444444\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6457777777777778\n",
      "\t\tEpoch: 2, Accuracy: 0.6426666666666667\n",
      "\t\tEpoch: 3, Accuracy: 0.652\n",
      "\t\tEpoch: 4, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 5, Accuracy: 0.6764444444444444\n",
      "\t\tEpoch: 6, Accuracy: 0.6755555555555556\n",
      "\t\tEpoch: 7, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 8, Accuracy: 0.6755555555555556\n",
      "\t\tEpoch: 9, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 10, Accuracy: 0.652\n",
      "\t\tEpoch: 11, Accuracy: 0.6751111111111111\n",
      "\t\tEpoch: 12, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 13, Accuracy: 0.6737777777777778\n",
      "\t\tEpoch: 14, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 15, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 16, Accuracy: 0.676\n",
      "\t\tEpoch: 17, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 18, Accuracy: 0.696\n",
      "\t\tEpoch: 19, Accuracy: 0.6742222222222222\n",
      "\t\tEpoch: 20, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 21, Accuracy: 0.6968888888888889\n",
      "\t\tEpoch: 22, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 23, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 24, Accuracy: 0.6795555555555556\n",
      "\t\tEpoch: 25, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 26, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 27, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 28, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 29, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 30, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 31, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 32, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 33, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 34, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 36, Accuracy: 0.692\n",
      "\t\tEpoch: 37, Accuracy: 0.6768888888888889\n",
      "\t\tEpoch: 38, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 39, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 40, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 41, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 42, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 43, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 44, Accuracy: 0.68\n",
      "\t\tEpoch: 45, Accuracy: 0.688\n",
      "\t\tEpoch: 46, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 47, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 48, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 49, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 50, Accuracy: 0.6937777777777778\n",
      "\n",
      "\tBest parameter: 0.1 & test accuracy:  0.7017777777777777\n",
      "\tTFIDF Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.6288888888888889\n",
      "\t\tEpoch: 2, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 3, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 4, Accuracy: 0.716\n",
      "\t\tEpoch: 5, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 6, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 7, Accuracy: 0.6222222222222222\n",
      "\t\tEpoch: 8, Accuracy: 0.688\n",
      "\t\tEpoch: 9, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 11, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 12, Accuracy: 0.6795555555555556\n",
      "\t\tEpoch: 13, Accuracy: 0.684\n",
      "\t\tEpoch: 14, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 15, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 16, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 17, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 18, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 19, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 20, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 22, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 23, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 24, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 25, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 26, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 27, Accuracy: 0.7031111111111111\n",
      "\t\tEpoch: 28, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 29, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 30, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 31, Accuracy: 0.6693333333333333\n",
      "\t\tEpoch: 32, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 33, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 34, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 35, Accuracy: 0.6582222222222223\n",
      "\t\tEpoch: 36, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 37, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 38, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 39, Accuracy: 0.6582222222222223\n",
      "\t\tEpoch: 40, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 41, Accuracy: 0.6746666666666666\n",
      "\t\tEpoch: 42, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 43, Accuracy: 0.6751111111111111\n",
      "\t\tEpoch: 44, Accuracy: 0.6733333333333333\n",
      "\t\tEpoch: 45, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.664\n",
      "\t\tEpoch: 47, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 48, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 49, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 50, Accuracy: 0.6684444444444444\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6173333333333333\n",
      "\t\tEpoch: 2, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 3, Accuracy: 0.6706666666666666\n",
      "\t\tEpoch: 4, Accuracy: 0.6368888888888888\n",
      "\t\tEpoch: 5, Accuracy: 0.6742222222222222\n",
      "\t\tEpoch: 6, Accuracy: 0.6795555555555556\n",
      "\t\tEpoch: 7, Accuracy: 0.6102222222222222\n",
      "\t\tEpoch: 8, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 9, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 11, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 12, Accuracy: 0.684\n",
      "\t\tEpoch: 13, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 14, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 15, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 16, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 17, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 18, Accuracy: 0.6515555555555556\n",
      "\t\tEpoch: 19, Accuracy: 0.692\n",
      "\t\tEpoch: 20, Accuracy: 0.7\n",
      "\t\tEpoch: 21, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 22, Accuracy: 0.7\n",
      "\t\tEpoch: 23, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 24, Accuracy: 0.692\n",
      "\t\tEpoch: 25, Accuracy: 0.6613333333333333\n",
      "\t\tEpoch: 26, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 27, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 28, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 29, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 30, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 31, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 32, Accuracy: 0.6533333333333333\n",
      "\t\tEpoch: 33, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 34, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 35, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 36, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 37, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 38, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 39, Accuracy: 0.696\n",
      "\t\tEpoch: 40, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 41, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 42, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 43, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 44, Accuracy: 0.684\n",
      "\t\tEpoch: 45, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 46, Accuracy: 0.6813333333333333\n",
      "\t\tEpoch: 47, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 48, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 49, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 50, Accuracy: 0.6733333333333333\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 2, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 3, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 4, Accuracy: 0.692\n",
      "\t\tEpoch: 5, Accuracy: 0.704\n",
      "\t\tEpoch: 6, Accuracy: 0.6817777777777778\n",
      "\t\tEpoch: 7, Accuracy: 0.6568888888888889\n",
      "\t\tEpoch: 8, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 9, Accuracy: 0.6791111111111111\n",
      "\t\tEpoch: 10, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 11, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 12, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 13, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 14, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 15, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 16, Accuracy: 0.6724444444444444\n",
      "\t\tEpoch: 17, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 18, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 19, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 20, Accuracy: 0.7177777777777777\n",
      "\t\tEpoch: 21, Accuracy: 0.6702222222222223\n",
      "\t\tEpoch: 22, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 23, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 24, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 25, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 26, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 27, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 28, Accuracy: 0.6386666666666667\n",
      "\t\tEpoch: 29, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 30, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 31, Accuracy: 0.684\n",
      "\t\tEpoch: 32, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 33, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 35, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 36, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 37, Accuracy: 0.688\n",
      "\t\tEpoch: 38, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 39, Accuracy: 0.688\n",
      "\t\tEpoch: 40, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 41, Accuracy: 0.68\n",
      "\t\tEpoch: 42, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 43, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 44, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 45, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.688\n",
      "\t\tEpoch: 47, Accuracy: 0.6826666666666666\n",
      "\t\tEpoch: 48, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 49, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 50, Accuracy: 0.6964444444444444\n",
      "\n",
      "\tBest parameter: 0.01 & test accuracy:  0.7177777777777777\n",
      "Average Perceptron\n",
      "\n",
      "\tGlove Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.6524444444444445\n",
      "\t\tEpoch: 2, Accuracy: 0.6577777777777778\n",
      "\t\tEpoch: 3, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 4, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 5, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 6, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 7, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 8, Accuracy: 0.6617777777777778\n",
      "\t\tEpoch: 9, Accuracy: 0.664\n",
      "\t\tEpoch: 10, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 11, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 12, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 13, Accuracy: 0.664\n",
      "\t\tEpoch: 14, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 15, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 16, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 17, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 18, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 19, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 20, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 22, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 23, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 24, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 25, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 26, Accuracy: 0.668\n",
      "\t\tEpoch: 27, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 28, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 29, Accuracy: 0.664\n",
      "\t\tEpoch: 30, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 31, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 32, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 33, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 34, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 35, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 36, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 37, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 38, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 39, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 40, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 41, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 42, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 43, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 44, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 45, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 46, Accuracy: 0.6613333333333333\n",
      "\t\tEpoch: 47, Accuracy: 0.6608888888888889\n",
      "\t\tEpoch: 48, Accuracy: 0.6613333333333333\n",
      "\t\tEpoch: 49, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 50, Accuracy: 0.6626666666666666\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6533333333333333\n",
      "\t\tEpoch: 2, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 3, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 4, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 5, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 6, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 7, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 8, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 9, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 10, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 11, Accuracy: 0.6617777777777778\n",
      "\t\tEpoch: 12, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 13, Accuracy: 0.664\n",
      "\t\tEpoch: 14, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 15, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 17, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 18, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 19, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 20, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 21, Accuracy: 0.6671111111111111\n",
      "\t\tEpoch: 22, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 23, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 24, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 25, Accuracy: 0.664\n",
      "\t\tEpoch: 26, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 27, Accuracy: 0.6635555555555556\n",
      "\t\tEpoch: 28, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 29, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 30, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 31, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 32, Accuracy: 0.664\n",
      "\t\tEpoch: 33, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 34, Accuracy: 0.6626666666666666\n",
      "\t\tEpoch: 35, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 37, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 38, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 39, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 40, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 41, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 42, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 43, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 44, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 45, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 47, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 48, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 49, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 50, Accuracy: 0.6653333333333333\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6497777777777778\n",
      "\t\tEpoch: 2, Accuracy: 0.6631111111111111\n",
      "\t\tEpoch: 3, Accuracy: 0.6622222222222223\n",
      "\t\tEpoch: 4, Accuracy: 0.6706666666666666\n",
      "\t\tEpoch: 5, Accuracy: 0.6693333333333333\n",
      "\t\tEpoch: 6, Accuracy: 0.6671111111111111\n",
      "\t\tEpoch: 7, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 8, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 9, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 10, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 11, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 12, Accuracy: 0.6688888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 14, Accuracy: 0.6706666666666666\n",
      "\t\tEpoch: 15, Accuracy: 0.6697777777777778\n",
      "\t\tEpoch: 16, Accuracy: 0.6688888888888889\n",
      "\t\tEpoch: 17, Accuracy: 0.6706666666666666\n",
      "\t\tEpoch: 18, Accuracy: 0.6671111111111111\n",
      "\t\tEpoch: 19, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 20, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 22, Accuracy: 0.668\n",
      "\t\tEpoch: 23, Accuracy: 0.6688888888888889\n",
      "\t\tEpoch: 24, Accuracy: 0.668\n",
      "\t\tEpoch: 25, Accuracy: 0.6693333333333333\n",
      "\t\tEpoch: 26, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 27, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 28, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 29, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 30, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 31, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 32, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 33, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 35, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 36, Accuracy: 0.6671111111111111\n",
      "\t\tEpoch: 37, Accuracy: 0.6675555555555556\n",
      "\t\tEpoch: 38, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 39, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 40, Accuracy: 0.6662222222222223\n",
      "\t\tEpoch: 41, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 42, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 43, Accuracy: 0.6666666666666666\n",
      "\t\tEpoch: 44, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 45, Accuracy: 0.6671111111111111\n",
      "\t\tEpoch: 46, Accuracy: 0.6657777777777778\n",
      "\t\tEpoch: 47, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 48, Accuracy: 0.6644444444444444\n",
      "\t\tEpoch: 49, Accuracy: 0.6653333333333333\n",
      "\t\tEpoch: 50, Accuracy: 0.6666666666666666\n",
      "\n",
      "\tBest parameter: 0.01 & test accuracy:  0.6706666666666666\n",
      "\tBOW Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 2, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 3, Accuracy: 0.692\n",
      "\t\tEpoch: 4, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 5, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 6, Accuracy: 0.704\n",
      "\t\tEpoch: 7, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 8, Accuracy: 0.7031111111111111\n",
      "\t\tEpoch: 9, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 10, Accuracy: 0.704\n",
      "\t\tEpoch: 11, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 12, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 13, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 14, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 15, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 16, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 17, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 18, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 19, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 20, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 21, Accuracy: 0.7\n",
      "\t\tEpoch: 22, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 23, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 24, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 25, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 26, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 27, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 28, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 29, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 30, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 31, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 32, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 33, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 34, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 35, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 36, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 37, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 38, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 39, Accuracy: 0.696\n",
      "\t\tEpoch: 40, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 41, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 42, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 43, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 44, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 45, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 47, Accuracy: 0.7031111111111111\n",
      "\t\tEpoch: 48, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 49, Accuracy: 0.704\n",
      "\t\tEpoch: 50, Accuracy: 0.7026666666666667\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6706666666666666\n",
      "\t\tEpoch: 2, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 3, Accuracy: 0.684\n",
      "\t\tEpoch: 4, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 5, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 6, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 7, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 8, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 9, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 10, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 11, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 12, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 14, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 15, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 16, Accuracy: 0.708\n",
      "\t\tEpoch: 17, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 18, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 19, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 20, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 21, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 22, Accuracy: 0.704\n",
      "\t\tEpoch: 23, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 24, Accuracy: 0.7\n",
      "\t\tEpoch: 25, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 26, Accuracy: 0.7\n",
      "\t\tEpoch: 27, Accuracy: 0.7\n",
      "\t\tEpoch: 28, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 29, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 30, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 31, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 32, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 33, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 34, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 35, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 36, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 37, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 38, Accuracy: 0.7\n",
      "\t\tEpoch: 39, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 40, Accuracy: 0.7\n",
      "\t\tEpoch: 41, Accuracy: 0.7\n",
      "\t\tEpoch: 42, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 43, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 44, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 45, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 47, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 48, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 49, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 50, Accuracy: 0.6991111111111111\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 2, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 3, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 4, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 5, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 6, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 7, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 8, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 9, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.7031111111111111\n",
      "\t\tEpoch: 11, Accuracy: 0.7031111111111111\n",
      "\t\tEpoch: 12, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 13, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 14, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 15, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 16, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 17, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 18, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 19, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 20, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 21, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 22, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 23, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 24, Accuracy: 0.708\n",
      "\t\tEpoch: 25, Accuracy: 0.708\n",
      "\t\tEpoch: 26, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 27, Accuracy: 0.708\n",
      "\t\tEpoch: 28, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 29, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 30, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 31, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 32, Accuracy: 0.704\n",
      "\t\tEpoch: 33, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 36, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 37, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 38, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 39, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 40, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 41, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 42, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 43, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 44, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 45, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 46, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 47, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 48, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 49, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 50, Accuracy: 0.704\n",
      "\n",
      "\tBest parameter: 0.1 & test accuracy:  0.7088888888888889\n",
      "\tTFIDF Dataset\n",
      "\n",
      "\tLearning rate: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.7155555555555555\n",
      "\t\tEpoch: 2, Accuracy: 0.7293333333333333\n",
      "\t\tEpoch: 3, Accuracy: 0.7262222222222222\n",
      "\t\tEpoch: 4, Accuracy: 0.7248888888888889\n",
      "\t\tEpoch: 5, Accuracy: 0.7226666666666667\n",
      "\t\tEpoch: 6, Accuracy: 0.724\n",
      "\t\tEpoch: 7, Accuracy: 0.7217777777777777\n",
      "\t\tEpoch: 8, Accuracy: 0.7195555555555555\n",
      "\t\tEpoch: 9, Accuracy: 0.7177777777777777\n",
      "\t\tEpoch: 10, Accuracy: 0.7164444444444444\n",
      "\t\tEpoch: 11, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 12, Accuracy: 0.7151111111111111\n",
      "\t\tEpoch: 13, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 14, Accuracy: 0.7102222222222222\n",
      "\t\tEpoch: 15, Accuracy: 0.7128888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.7124444444444444\n",
      "\t\tEpoch: 17, Accuracy: 0.7137777777777777\n",
      "\t\tEpoch: 18, Accuracy: 0.7128888888888889\n",
      "\t\tEpoch: 19, Accuracy: 0.712\n",
      "\t\tEpoch: 20, Accuracy: 0.712\n",
      "\t\tEpoch: 21, Accuracy: 0.7151111111111111\n",
      "\t\tEpoch: 22, Accuracy: 0.7155555555555555\n",
      "\t\tEpoch: 23, Accuracy: 0.7173333333333334\n",
      "\t\tEpoch: 24, Accuracy: 0.7164444444444444\n",
      "\t\tEpoch: 25, Accuracy: 0.7137777777777777\n",
      "\t\tEpoch: 26, Accuracy: 0.7124444444444444\n",
      "\t\tEpoch: 27, Accuracy: 0.7124444444444444\n",
      "\t\tEpoch: 28, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 30, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 31, Accuracy: 0.712\n",
      "\t\tEpoch: 32, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 33, Accuracy: 0.712\n",
      "\t\tEpoch: 34, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 35, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 37, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 38, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 39, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 40, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 41, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 42, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 43, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 44, Accuracy: 0.704\n",
      "\t\tEpoch: 45, Accuracy: 0.704\n",
      "\t\tEpoch: 46, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 47, Accuracy: 0.704\n",
      "\t\tEpoch: 48, Accuracy: 0.704\n",
      "\t\tEpoch: 49, Accuracy: 0.704\n",
      "\t\tEpoch: 50, Accuracy: 0.7048888888888889\n",
      "\n",
      "\tLearning rate: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 2, Accuracy: 0.7133333333333334\n",
      "\t\tEpoch: 3, Accuracy: 0.7173333333333334\n",
      "\t\tEpoch: 4, Accuracy: 0.7226666666666667\n",
      "\t\tEpoch: 5, Accuracy: 0.7244444444444444\n",
      "\t\tEpoch: 6, Accuracy: 0.7204444444444444\n",
      "\t\tEpoch: 7, Accuracy: 0.7231111111111111\n",
      "\t\tEpoch: 8, Accuracy: 0.7235555555555555\n",
      "\t\tEpoch: 9, Accuracy: 0.7253333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.72\n",
      "\t\tEpoch: 11, Accuracy: 0.7177777777777777\n",
      "\t\tEpoch: 12, Accuracy: 0.7164444444444444\n",
      "\t\tEpoch: 13, Accuracy: 0.716\n",
      "\t\tEpoch: 14, Accuracy: 0.7177777777777777\n",
      "\t\tEpoch: 15, Accuracy: 0.7155555555555555\n",
      "\t\tEpoch: 16, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 17, Accuracy: 0.7142222222222222\n",
      "\t\tEpoch: 18, Accuracy: 0.7137777777777777\n",
      "\t\tEpoch: 19, Accuracy: 0.7133333333333334\n",
      "\t\tEpoch: 20, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.712\n",
      "\t\tEpoch: 22, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 23, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 24, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 25, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 26, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 27, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 28, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 29, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 30, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 31, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 32, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 33, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 34, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 35, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 36, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 37, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 38, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 39, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 40, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 41, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 42, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 43, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 44, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 45, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 46, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 47, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 48, Accuracy: 0.704\n",
      "\t\tEpoch: 49, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 50, Accuracy: 0.7031111111111111\n",
      "\n",
      "\tLearning rate: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 2, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 3, Accuracy: 0.7186666666666667\n",
      "\t\tEpoch: 4, Accuracy: 0.7186666666666667\n",
      "\t\tEpoch: 5, Accuracy: 0.7195555555555555\n",
      "\t\tEpoch: 6, Accuracy: 0.7195555555555555\n",
      "\t\tEpoch: 7, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 8, Accuracy: 0.7173333333333334\n",
      "\t\tEpoch: 9, Accuracy: 0.7213333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.7235555555555555\n",
      "\t\tEpoch: 11, Accuracy: 0.7208888888888889\n",
      "\t\tEpoch: 12, Accuracy: 0.7204444444444444\n",
      "\t\tEpoch: 13, Accuracy: 0.7195555555555555\n",
      "\t\tEpoch: 14, Accuracy: 0.7177777777777777\n",
      "\t\tEpoch: 15, Accuracy: 0.7168888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.7195555555555555\n",
      "\t\tEpoch: 17, Accuracy: 0.716\n",
      "\t\tEpoch: 18, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 19, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 20, Accuracy: 0.7128888888888889\n",
      "\t\tEpoch: 21, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 22, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 23, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 24, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 25, Accuracy: 0.712\n",
      "\t\tEpoch: 26, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 27, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 28, Accuracy: 0.7102222222222222\n",
      "\t\tEpoch: 29, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 30, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 31, Accuracy: 0.7128888888888889\n",
      "\t\tEpoch: 32, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 33, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 34, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 35, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 37, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 38, Accuracy: 0.708\n",
      "\t\tEpoch: 39, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 40, Accuracy: 0.7093333333333334\n",
      "\t\tEpoch: 41, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 42, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 43, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 44, Accuracy: 0.708\n",
      "\t\tEpoch: 45, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 46, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 47, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 48, Accuracy: 0.708\n",
      "\t\tEpoch: 49, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 50, Accuracy: 0.7075555555555556\n",
      "\n",
      "\tBest parameter: 1 & test accuracy:  0.7293333333333333\n",
      "Aggressive Perceptron\n",
      "\n",
      "\tGlove Dataset\n",
      "\n",
      "\tMargin: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.5804444444444444\n",
      "\t\tEpoch: 2, Accuracy: 0.6204444444444445\n",
      "\t\tEpoch: 3, Accuracy: 0.6\n",
      "\t\tEpoch: 4, Accuracy: 0.608\n",
      "\t\tEpoch: 5, Accuracy: 0.548\n",
      "\t\tEpoch: 6, Accuracy: 0.5595555555555556\n",
      "\t\tEpoch: 7, Accuracy: 0.5911111111111111\n",
      "\t\tEpoch: 8, Accuracy: 0.576\n",
      "\t\tEpoch: 9, Accuracy: 0.6253333333333333\n",
      "\t\tEpoch: 10, Accuracy: 0.5591111111111111\n",
      "\t\tEpoch: 11, Accuracy: 0.6408888888888888\n",
      "\t\tEpoch: 12, Accuracy: 0.6311111111111111\n",
      "\t\tEpoch: 13, Accuracy: 0.6306666666666667\n",
      "\t\tEpoch: 14, Accuracy: 0.6413333333333333\n",
      "\t\tEpoch: 15, Accuracy: 0.5186666666666667\n",
      "\t\tEpoch: 16, Accuracy: 0.6222222222222222\n",
      "\t\tEpoch: 17, Accuracy: 0.6324444444444445\n",
      "\t\tEpoch: 18, Accuracy: 0.5653333333333334\n",
      "\t\tEpoch: 19, Accuracy: 0.6213333333333333\n",
      "\t\tEpoch: 20, Accuracy: 0.5826666666666667\n",
      "\t\tEpoch: 21, Accuracy: 0.6168888888888889\n",
      "\t\tEpoch: 22, Accuracy: 0.5262222222222223\n",
      "\t\tEpoch: 23, Accuracy: 0.5795555555555556\n",
      "\t\tEpoch: 24, Accuracy: 0.5844444444444444\n",
      "\t\tEpoch: 25, Accuracy: 0.5955555555555555\n",
      "\t\tEpoch: 26, Accuracy: 0.6253333333333333\n",
      "\t\tEpoch: 27, Accuracy: 0.6235555555555555\n",
      "\t\tEpoch: 28, Accuracy: 0.5946666666666667\n",
      "\t\tEpoch: 29, Accuracy: 0.5991111111111111\n",
      "\t\tEpoch: 30, Accuracy: 0.6204444444444445\n",
      "\t\tEpoch: 31, Accuracy: 0.6208888888888889\n",
      "\t\tEpoch: 32, Accuracy: 0.5697777777777778\n",
      "\t\tEpoch: 33, Accuracy: 0.6062222222222222\n",
      "\t\tEpoch: 34, Accuracy: 0.5533333333333333\n",
      "\t\tEpoch: 35, Accuracy: 0.5608888888888889\n",
      "\t\tEpoch: 36, Accuracy: 0.5262222222222223\n",
      "\t\tEpoch: 37, Accuracy: 0.6164444444444445\n",
      "\t\tEpoch: 38, Accuracy: 0.5915555555555555\n",
      "\t\tEpoch: 39, Accuracy: 0.5804444444444444\n",
      "\t\tEpoch: 40, Accuracy: 0.5764444444444444\n",
      "\t\tEpoch: 41, Accuracy: 0.6173333333333333\n",
      "\t\tEpoch: 42, Accuracy: 0.5417777777777778\n",
      "\t\tEpoch: 43, Accuracy: 0.6075555555555555\n",
      "\t\tEpoch: 44, Accuracy: 0.5804444444444444\n",
      "\t\tEpoch: 45, Accuracy: 0.5244444444444445\n",
      "\t\tEpoch: 46, Accuracy: 0.6204444444444445\n",
      "\t\tEpoch: 47, Accuracy: 0.5084444444444445\n",
      "\t\tEpoch: 48, Accuracy: 0.5893333333333334\n",
      "\t\tEpoch: 49, Accuracy: 0.584\n",
      "\t\tEpoch: 50, Accuracy: 0.5568888888888889\n",
      "\n",
      "\tMargin: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6017777777777777\n",
      "\t\tEpoch: 2, Accuracy: 0.5617777777777778\n",
      "\t\tEpoch: 3, Accuracy: 0.624\n",
      "\t\tEpoch: 4, Accuracy: 0.5622222222222222\n",
      "\t\tEpoch: 5, Accuracy: 0.5893333333333334\n",
      "\t\tEpoch: 6, Accuracy: 0.6128888888888889\n",
      "\t\tEpoch: 7, Accuracy: 0.532\n",
      "\t\tEpoch: 8, Accuracy: 0.5826666666666667\n",
      "\t\tEpoch: 9, Accuracy: 0.6137777777777778\n",
      "\t\tEpoch: 10, Accuracy: 0.588\n",
      "\t\tEpoch: 11, Accuracy: 0.6075555555555555\n",
      "\t\tEpoch: 12, Accuracy: 0.5262222222222223\n",
      "\t\tEpoch: 13, Accuracy: 0.6226666666666667\n",
      "\t\tEpoch: 14, Accuracy: 0.5933333333333334\n",
      "\t\tEpoch: 15, Accuracy: 0.6133333333333333\n",
      "\t\tEpoch: 16, Accuracy: 0.5488888888888889\n",
      "\t\tEpoch: 17, Accuracy: 0.6342222222222222\n",
      "\t\tEpoch: 18, Accuracy: 0.5737777777777778\n",
      "\t\tEpoch: 19, Accuracy: 0.5964444444444444\n",
      "\t\tEpoch: 20, Accuracy: 0.6071111111111112\n",
      "\t\tEpoch: 21, Accuracy: 0.6102222222222222\n",
      "\t\tEpoch: 22, Accuracy: 0.6257777777777778\n",
      "\t\tEpoch: 23, Accuracy: 0.6364444444444445\n",
      "\t\tEpoch: 24, Accuracy: 0.616\n",
      "\t\tEpoch: 25, Accuracy: 0.592\n",
      "\t\tEpoch: 26, Accuracy: 0.5702222222222222\n",
      "\t\tEpoch: 27, Accuracy: 0.6084444444444445\n",
      "\t\tEpoch: 28, Accuracy: 0.6195555555555555\n",
      "\t\tEpoch: 29, Accuracy: 0.62\n",
      "\t\tEpoch: 30, Accuracy: 0.5222222222222223\n",
      "\t\tEpoch: 31, Accuracy: 0.604\n",
      "\t\tEpoch: 32, Accuracy: 0.5764444444444444\n",
      "\t\tEpoch: 33, Accuracy: 0.6062222222222222\n",
      "\t\tEpoch: 34, Accuracy: 0.6306666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.612\n",
      "\t\tEpoch: 36, Accuracy: 0.5493333333333333\n",
      "\t\tEpoch: 37, Accuracy: 0.5444444444444444\n",
      "\t\tEpoch: 38, Accuracy: 0.6102222222222222\n",
      "\t\tEpoch: 39, Accuracy: 0.624\n",
      "\t\tEpoch: 40, Accuracy: 0.5284444444444445\n",
      "\t\tEpoch: 41, Accuracy: 0.6208888888888889\n",
      "\t\tEpoch: 42, Accuracy: 0.5786666666666667\n",
      "\t\tEpoch: 43, Accuracy: 0.5293333333333333\n",
      "\t\tEpoch: 44, Accuracy: 0.5715555555555556\n",
      "\t\tEpoch: 45, Accuracy: 0.6111111111111112\n",
      "\t\tEpoch: 46, Accuracy: 0.5631111111111111\n",
      "\t\tEpoch: 47, Accuracy: 0.5728888888888889\n",
      "\t\tEpoch: 48, Accuracy: 0.5533333333333333\n",
      "\t\tEpoch: 49, Accuracy: 0.6044444444444445\n",
      "\t\tEpoch: 50, Accuracy: 0.5271111111111111\n",
      "\n",
      "\tMargin: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.5871111111111111\n",
      "\t\tEpoch: 2, Accuracy: 0.5897777777777777\n",
      "\t\tEpoch: 3, Accuracy: 0.5453333333333333\n",
      "\t\tEpoch: 4, Accuracy: 0.5733333333333334\n",
      "\t\tEpoch: 5, Accuracy: 0.5191111111111111\n",
      "\t\tEpoch: 6, Accuracy: 0.5964444444444444\n",
      "\t\tEpoch: 7, Accuracy: 0.5346666666666666\n",
      "\t\tEpoch: 8, Accuracy: 0.608\n",
      "\t\tEpoch: 9, Accuracy: 0.5991111111111111\n",
      "\t\tEpoch: 10, Accuracy: 0.5786666666666667\n",
      "\t\tEpoch: 11, Accuracy: 0.6262222222222222\n",
      "\t\tEpoch: 12, Accuracy: 0.576\n",
      "\t\tEpoch: 13, Accuracy: 0.6017777777777777\n",
      "\t\tEpoch: 14, Accuracy: 0.5346666666666666\n",
      "\t\tEpoch: 15, Accuracy: 0.5768888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.5955555555555555\n",
      "\t\tEpoch: 17, Accuracy: 0.584\n",
      "\t\tEpoch: 18, Accuracy: 0.5697777777777778\n",
      "\t\tEpoch: 19, Accuracy: 0.608\n",
      "\t\tEpoch: 20, Accuracy: 0.5635555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.5951111111111111\n",
      "\t\tEpoch: 22, Accuracy: 0.5795555555555556\n",
      "\t\tEpoch: 23, Accuracy: 0.5991111111111111\n",
      "\t\tEpoch: 24, Accuracy: 0.6351111111111111\n",
      "\t\tEpoch: 25, Accuracy: 0.6426666666666667\n",
      "\t\tEpoch: 26, Accuracy: 0.64\n",
      "\t\tEpoch: 27, Accuracy: 0.612\n",
      "\t\tEpoch: 28, Accuracy: 0.6111111111111112\n",
      "\t\tEpoch: 29, Accuracy: 0.5706666666666667\n",
      "\t\tEpoch: 30, Accuracy: 0.5022222222222222\n",
      "\t\tEpoch: 31, Accuracy: 0.5915555555555555\n",
      "\t\tEpoch: 32, Accuracy: 0.6115555555555555\n",
      "\t\tEpoch: 33, Accuracy: 0.5813333333333334\n",
      "\t\tEpoch: 34, Accuracy: 0.6066666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.548\n",
      "\t\tEpoch: 36, Accuracy: 0.6191111111111111\n",
      "\t\tEpoch: 37, Accuracy: 0.6355555555555555\n",
      "\t\tEpoch: 38, Accuracy: 0.6013333333333334\n",
      "\t\tEpoch: 39, Accuracy: 0.5746666666666667\n",
      "\t\tEpoch: 40, Accuracy: 0.5408888888888889\n",
      "\t\tEpoch: 41, Accuracy: 0.628\n",
      "\t\tEpoch: 42, Accuracy: 0.512\n",
      "\t\tEpoch: 43, Accuracy: 0.6253333333333333\n",
      "\t\tEpoch: 44, Accuracy: 0.6191111111111111\n",
      "\t\tEpoch: 45, Accuracy: 0.5902222222222222\n",
      "\t\tEpoch: 46, Accuracy: 0.5426666666666666\n",
      "\t\tEpoch: 47, Accuracy: 0.588\n",
      "\t\tEpoch: 48, Accuracy: 0.5524444444444444\n",
      "\t\tEpoch: 49, Accuracy: 0.6186666666666667\n",
      "\t\tEpoch: 50, Accuracy: 0.5453333333333333\n",
      "\n",
      "\tBest parameter: 0.01 & test accuracy:  0.6426666666666667\n",
      "\tBOW Dataset\n",
      "\n",
      "\tMargin: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.692\n",
      "\t\tEpoch: 2, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 3, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 4, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 5, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 6, Accuracy: 0.6751111111111111\n",
      "\t\tEpoch: 7, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 8, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 9, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 10, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 11, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 12, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 13, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 14, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 15, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 16, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 17, Accuracy: 0.6817777777777778\n",
      "\t\tEpoch: 18, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 19, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 20, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 21, Accuracy: 0.692\n",
      "\t\tEpoch: 22, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 23, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 24, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 25, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 26, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 27, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 28, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 29, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 30, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 31, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 32, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 33, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 34, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 35, Accuracy: 0.688\n",
      "\t\tEpoch: 36, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 37, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 38, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 39, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 40, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 41, Accuracy: 0.688\n",
      "\t\tEpoch: 42, Accuracy: 0.684\n",
      "\t\tEpoch: 43, Accuracy: 0.6755555555555556\n",
      "\t\tEpoch: 44, Accuracy: 0.696\n",
      "\t\tEpoch: 45, Accuracy: 0.6782222222222222\n",
      "\t\tEpoch: 46, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 47, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 48, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 49, Accuracy: 0.68\n",
      "\t\tEpoch: 50, Accuracy: 0.6826666666666666\n",
      "\n",
      "\tMargin: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 2, Accuracy: 0.6702222222222223\n",
      "\t\tEpoch: 3, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 4, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 5, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 6, Accuracy: 0.6817777777777778\n",
      "\t\tEpoch: 7, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 8, Accuracy: 0.696\n",
      "\t\tEpoch: 9, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 10, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 11, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 12, Accuracy: 0.6853333333333333\n",
      "\t\tEpoch: 13, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 14, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 15, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 16, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 17, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 18, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 19, Accuracy: 0.684\n",
      "\t\tEpoch: 20, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 21, Accuracy: 0.6746666666666666\n",
      "\t\tEpoch: 22, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 23, Accuracy: 0.688\n",
      "\t\tEpoch: 24, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 25, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 26, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 27, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 28, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 30, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 31, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 32, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 33, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 35, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 37, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 38, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 39, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 40, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 41, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 42, Accuracy: 0.692\n",
      "\t\tEpoch: 43, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 44, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 45, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 46, Accuracy: 0.692\n",
      "\t\tEpoch: 47, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 48, Accuracy: 0.688\n",
      "\t\tEpoch: 49, Accuracy: 0.6791111111111111\n",
      "\t\tEpoch: 50, Accuracy: 0.6817777777777778\n",
      "\n",
      "\tMargin: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6586666666666666\n",
      "\t\tEpoch: 2, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 3, Accuracy: 0.6813333333333333\n",
      "\t\tEpoch: 4, Accuracy: 0.6791111111111111\n",
      "\t\tEpoch: 5, Accuracy: 0.6786666666666666\n",
      "\t\tEpoch: 6, Accuracy: 0.68\n",
      "\t\tEpoch: 7, Accuracy: 0.6848888888888889\n",
      "\t\tEpoch: 8, Accuracy: 0.6826666666666666\n",
      "\t\tEpoch: 9, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 10, Accuracy: 0.6742222222222222\n",
      "\t\tEpoch: 11, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 12, Accuracy: 0.6848888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.6728888888888889\n",
      "\t\tEpoch: 14, Accuracy: 0.6888888888888889\n",
      "\t\tEpoch: 15, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 17, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 18, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 19, Accuracy: 0.6884444444444444\n",
      "\t\tEpoch: 20, Accuracy: 0.6902222222222222\n",
      "\t\tEpoch: 21, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 22, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 23, Accuracy: 0.6791111111111111\n",
      "\t\tEpoch: 24, Accuracy: 0.6866666666666666\n",
      "\t\tEpoch: 25, Accuracy: 0.6773333333333333\n",
      "\t\tEpoch: 26, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 27, Accuracy: 0.6857777777777778\n",
      "\t\tEpoch: 28, Accuracy: 0.6791111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 30, Accuracy: 0.6848888888888889\n",
      "\t\tEpoch: 31, Accuracy: 0.688\n",
      "\t\tEpoch: 32, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 33, Accuracy: 0.6768888888888889\n",
      "\t\tEpoch: 34, Accuracy: 0.6737777777777778\n",
      "\t\tEpoch: 35, Accuracy: 0.6871111111111111\n",
      "\t\tEpoch: 36, Accuracy: 0.6795555555555556\n",
      "\t\tEpoch: 37, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 38, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 39, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 40, Accuracy: 0.6813333333333333\n",
      "\t\tEpoch: 41, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 42, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 43, Accuracy: 0.6835555555555556\n",
      "\t\tEpoch: 44, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 45, Accuracy: 0.6786666666666666\n",
      "\t\tEpoch: 46, Accuracy: 0.6777777777777778\n",
      "\t\tEpoch: 47, Accuracy: 0.68\n",
      "\t\tEpoch: 48, Accuracy: 0.6822222222222222\n",
      "\t\tEpoch: 49, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 50, Accuracy: 0.6928888888888889\n",
      "\n",
      "\tBest parameter: 1 & test accuracy:  0.7071111111111111\n",
      "\tTFIDF Dataset\n",
      "\n",
      "\tMargin: 1\n",
      "\t\tEpoch: 1, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 2, Accuracy: 0.7275555555555555\n",
      "\t\tEpoch: 3, Accuracy: 0.7164444444444444\n",
      "\t\tEpoch: 4, Accuracy: 0.7111111111111111\n",
      "\t\tEpoch: 5, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 6, Accuracy: 0.7137777777777777\n",
      "\t\tEpoch: 7, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 8, Accuracy: 0.6733333333333333\n",
      "\t\tEpoch: 9, Accuracy: 0.7128888888888889\n",
      "\t\tEpoch: 10, Accuracy: 0.716\n",
      "\t\tEpoch: 11, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 12, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 14, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 15, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 16, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 17, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 18, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 19, Accuracy: 0.708\n",
      "\t\tEpoch: 20, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 21, Accuracy: 0.7106666666666667\n",
      "\t\tEpoch: 22, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 23, Accuracy: 0.704\n",
      "\t\tEpoch: 24, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 25, Accuracy: 0.7\n",
      "\t\tEpoch: 26, Accuracy: 0.7\n",
      "\t\tEpoch: 27, Accuracy: 0.7093333333333334\n",
      "\t\tEpoch: 28, Accuracy: 0.6831111111111111\n",
      "\t\tEpoch: 29, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 30, Accuracy: 0.696\n",
      "\t\tEpoch: 31, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 32, Accuracy: 0.6804444444444444\n",
      "\t\tEpoch: 33, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 34, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 35, Accuracy: 0.6808888888888889\n",
      "\t\tEpoch: 36, Accuracy: 0.7057777777777777\n",
      "\t\tEpoch: 37, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 38, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 39, Accuracy: 0.6768888888888889\n",
      "\t\tEpoch: 40, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 41, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 42, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 43, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 44, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 45, Accuracy: 0.6906666666666667\n",
      "\t\tEpoch: 46, Accuracy: 0.6724444444444444\n",
      "\t\tEpoch: 47, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 48, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 49, Accuracy: 0.696\n",
      "\t\tEpoch: 50, Accuracy: 0.6862222222222222\n",
      "\n",
      "\tMargin: 0.1\n",
      "\t\tEpoch: 1, Accuracy: 0.6786666666666666\n",
      "\t\tEpoch: 2, Accuracy: 0.716\n",
      "\t\tEpoch: 3, Accuracy: 0.708\n",
      "\t\tEpoch: 4, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 5, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 6, Accuracy: 0.7093333333333334\n",
      "\t\tEpoch: 7, Accuracy: 0.6502222222222223\n",
      "\t\tEpoch: 8, Accuracy: 0.7168888888888889\n",
      "\t\tEpoch: 9, Accuracy: 0.6915555555555556\n",
      "\t\tEpoch: 10, Accuracy: 0.708\n",
      "\t\tEpoch: 11, Accuracy: 0.7084444444444444\n",
      "\t\tEpoch: 12, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 13, Accuracy: 0.7137777777777777\n",
      "\t\tEpoch: 14, Accuracy: 0.7071111111111111\n",
      "\t\tEpoch: 15, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 16, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 17, Accuracy: 0.6924444444444444\n",
      "\t\tEpoch: 18, Accuracy: 0.6764444444444444\n",
      "\t\tEpoch: 19, Accuracy: 0.696\n",
      "\t\tEpoch: 20, Accuracy: 0.7022222222222222\n",
      "\t\tEpoch: 21, Accuracy: 0.6648888888888889\n",
      "\t\tEpoch: 22, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 23, Accuracy: 0.712\n",
      "\t\tEpoch: 24, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 25, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 26, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 27, Accuracy: 0.7026666666666667\n",
      "\t\tEpoch: 28, Accuracy: 0.7053333333333334\n",
      "\t\tEpoch: 29, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 30, Accuracy: 0.7044444444444444\n",
      "\t\tEpoch: 31, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 32, Accuracy: 0.6862222222222222\n",
      "\t\tEpoch: 33, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 34, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 35, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 36, Accuracy: 0.6848888888888889\n",
      "\t\tEpoch: 37, Accuracy: 0.6875555555555556\n",
      "\t\tEpoch: 38, Accuracy: 0.6911111111111111\n",
      "\t\tEpoch: 39, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 40, Accuracy: 0.6991111111111111\n",
      "\t\tEpoch: 41, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 42, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 43, Accuracy: 0.692\n",
      "\t\tEpoch: 44, Accuracy: 0.6946666666666667\n",
      "\t\tEpoch: 45, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 46, Accuracy: 0.6937777777777778\n",
      "\t\tEpoch: 47, Accuracy: 0.6515555555555556\n",
      "\t\tEpoch: 48, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 49, Accuracy: 0.692\n",
      "\t\tEpoch: 50, Accuracy: 0.6884444444444444\n",
      "\n",
      "\tMargin: 0.01\n",
      "\t\tEpoch: 1, Accuracy: 0.6533333333333333\n",
      "\t\tEpoch: 2, Accuracy: 0.7146666666666667\n",
      "\t\tEpoch: 3, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 4, Accuracy: 0.6844444444444444\n",
      "\t\tEpoch: 5, Accuracy: 0.6728888888888889\n",
      "\t\tEpoch: 6, Accuracy: 0.6982222222222222\n",
      "\t\tEpoch: 7, Accuracy: 0.6235555555555555\n",
      "\t\tEpoch: 8, Accuracy: 0.7066666666666667\n",
      "\t\tEpoch: 9, Accuracy: 0.6928888888888889\n",
      "\t\tEpoch: 10, Accuracy: 0.7035555555555556\n",
      "\t\tEpoch: 11, Accuracy: 0.6728888888888889\n",
      "\t\tEpoch: 12, Accuracy: 0.7048888888888889\n",
      "\t\tEpoch: 13, Accuracy: 0.6968888888888889\n",
      "\t\tEpoch: 14, Accuracy: 0.6897777777777778\n",
      "\t\tEpoch: 15, Accuracy: 0.7088888888888889\n",
      "\t\tEpoch: 16, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 17, Accuracy: 0.7075555555555556\n",
      "\t\tEpoch: 18, Accuracy: 0.7097777777777777\n",
      "\t\tEpoch: 19, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 20, Accuracy: 0.7115555555555556\n",
      "\t\tEpoch: 21, Accuracy: 0.7013333333333334\n",
      "\t\tEpoch: 22, Accuracy: 0.7004444444444444\n",
      "\t\tEpoch: 23, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 24, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 25, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 26, Accuracy: 0.7062222222222222\n",
      "\t\tEpoch: 27, Accuracy: 0.664\n",
      "\t\tEpoch: 28, Accuracy: 0.6742222222222222\n",
      "\t\tEpoch: 29, Accuracy: 0.6995555555555556\n",
      "\t\tEpoch: 30, Accuracy: 0.696\n",
      "\t\tEpoch: 31, Accuracy: 0.6942222222222222\n",
      "\t\tEpoch: 32, Accuracy: 0.696\n",
      "\t\tEpoch: 33, Accuracy: 0.7\n",
      "\t\tEpoch: 34, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 35, Accuracy: 0.6986666666666667\n",
      "\t\tEpoch: 36, Accuracy: 0.6973333333333334\n",
      "\t\tEpoch: 37, Accuracy: 0.7017777777777777\n",
      "\t\tEpoch: 38, Accuracy: 0.7\n",
      "\t\tEpoch: 39, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 40, Accuracy: 0.6893333333333334\n",
      "\t\tEpoch: 41, Accuracy: 0.692\n",
      "\t\tEpoch: 42, Accuracy: 0.7008888888888889\n",
      "\t\tEpoch: 43, Accuracy: 0.6968888888888889\n",
      "\t\tEpoch: 44, Accuracy: 0.696\n",
      "\t\tEpoch: 45, Accuracy: 0.6955555555555556\n",
      "\t\tEpoch: 46, Accuracy: 0.6977777777777778\n",
      "\t\tEpoch: 47, Accuracy: 0.6933333333333334\n",
      "\t\tEpoch: 48, Accuracy: 0.6951111111111111\n",
      "\t\tEpoch: 49, Accuracy: 0.6964444444444444\n",
      "\t\tEpoch: 50, Accuracy: 0.6955555555555556\n",
      "\n",
      "\tBest parameter: 1 & test accuracy:  0.7275555555555555\n"
     ]
    }
   ],
   "source": [
    "dataset_setup_dict = {\n",
    "    \"Glove\": {\"Train\": glove_df_train, \"Test\": glove_df_test, \"Eval\": glove_df_eval},\n",
    "    \"BOW\": {\"Train\": bow_df_train, \"Test\": bow_df_test, \"Eval\": bow_df_eval},\n",
    "    \"TFIDF\": {\"Train\": tfidf_df_train, \"Test\": tfidf_df_test, \"Eval\": tfidf_df_eval},\n",
    "}\n",
    "\n",
    "train_setup_dict = {\n",
    "    \"PerceptronMap\": {\n",
    "        \"Simple\": simple_perceptron_setup,\n",
    "        \"Average\": average_perceptron_setup,\n",
    "        \"Aggressive\": aggressive_perceptron_setup,\n",
    "    },\n",
    "    # \"Datasets\": [\"Glove\"],\n",
    "    # \"Datasets\": [\"BOW\"],\n",
    "    # \"Datasets\": [\"TFIDF\"],\n",
    "    \"Datasets\": [\"Glove\", \"BOW\", \"TFIDF\"],\n",
    "    # \"PerceptronSetups\": [\"Simple\"],\n",
    "    # \"PerceptronSetups\": [\"Average\"],\n",
    "    # \"PerceptronSetups\": [\"Aggressive\"],\n",
    "    \"PerceptronSetups\": [\"Simple\", \"Average\", \"Aggressive\"]\n",
    "}\n",
    "\n",
    "\n",
    "def train_setup():\n",
    "    for perceptron in train_setup_dict[\"PerceptronSetups\"]:\n",
    "        for dataset in train_setup_dict[\"Datasets\"]:\n",
    "            print(f\"\\n{perceptron} Perceptron: {dataset} Dataset\\n\")\n",
    "\n",
    "            best_hyper_param, best_accuracy, best_weights = train_setup_dict[\"PerceptronMap\"][perceptron](\n",
    "                dataset_setup_dict[dataset][\"Train\"], dataset_setup_dict[dataset][\"Test\"]\n",
    "            )\n",
    "\n",
    "            print(f\"\\n\\tBest parameter: {best_hyper_param} & test accuracy: \", best_accuracy)\n",
    "\n",
    "            export_file_name = \"{0}_perceptron_{1}_eval_dataset_prediction.csv\".format(\n",
    "                perceptron.lower(), dataset.lower()\n",
    "            )\n",
    "            _, prediction_list = test_accuracy(dataset_setup_dict[dataset][\"Eval\"], best_weights, store_eval=True)\n",
    "            export_prediction_to_csv(export_file_name, prediction_list)\n",
    "\n",
    "\n",
    "train_setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
